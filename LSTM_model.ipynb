{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import read_excel\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from pmdarima import pipeline, preprocessing as ppc, arima\n",
    "from pmdarima import auto_arima\n",
    "import pandas.testing as tm\n",
    "import keras\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, LSTM, Bidirectional\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import r2_score, make_scorer, mean_squared_error as mse, mean_absolute_error as mae\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge datasets\n",
    "\n",
    "# load datasets\n",
    "dataset1 = 'Session-Details-Summary-20190520 Bauerle.xlsx'\n",
    "dataset2 = 'Session-Details-Summary-20190520 downtown campus.xlsx'\n",
    "dataset3 = 'Session-Details-Summary-20190520 1604 campus.xlsx'\n",
    "\n",
    "# read datasets\n",
    "df1 = pd.read_excel(dataset1)\n",
    "df2 = pd.read_excel(dataset2)\n",
    "df3 = pd.read_excel(dataset3)\n",
    "\n",
    "# extract colummns to be used\n",
    "values1 = df1[['Transaction Date (Pacific Time)', 'Energy (kWh)']]\n",
    "values2 = df2[['Transaction Date (Pacific Time)', 'Energy (kWh)']]\n",
    "values3 = df3[['Transaction Date (Pacific Time)', 'Energy (kWh)']]\n",
    "\n",
    "# create a new dataframe with all joined datasets\n",
    "dataframes = [values1, values2, values3]\n",
    "join = pd.concat(dataframes)\n",
    "\n",
    "# save to new csv file called data \n",
    "# csv is better output format because of dates\n",
    "join.to_csv('data.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read new dataset\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# filter desired rows from dataset\n",
    "data_ranges = [slice(0, 124), slice(134, 220), slice(247, 277), slice(288, 553), slice(704, 867), slice(873, 1015)]\n",
    "data = pd.concat(data.iloc[x, :] for x in data_ranges)\n",
    "\n",
    "# rename columns and set index\n",
    "data.set_index('Transaction Date (Pacific Time)', inplace= True)\n",
    "data.index.name = 'date'\n",
    "data.columns = [\"power\"]\n",
    "\n",
    "#convert from energy (kWh) to power (kW) \n",
    "data.index = pd.to_datetime(data.index)\n",
    "data = data[data.index.dayofweek < 5].sort_values(by=\"date\")\n",
    "print(data.head(20))\n",
    "data.describe()\n",
    "# make sure all values are numeric\n",
    "data = data.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary table indicates that most of the dataset is centered around 6 and dispersion is also 6, that means that maximum value can be considered anomaly in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize time series \n",
    "\n",
    "fig = plt.figure(figsize=(18,16))\n",
    "ax = fig.add_subplot(5,1,1)\n",
    "ax.plot(data,linewidth=1)\n",
    "ax.set_title('Load power resampled over day')\n",
    "ax.tick_params(axis='both', which='major')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Load Energy (kW)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to look at p-value to know if time series is stationary\n",
    "def adf_test(timeseries):\n",
    "    #Perform Dickey-Fuller test:\n",
    "    print ('Results of Dickey-Fuller Test:')\n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "       dfoutput['Critical Value (%s)'%key] = value\n",
    "    print (dfoutput)\n",
    "\n",
    "print(adf_test(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P-value indicates that series is stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seasonal decomposition will help to see we have seasonal pattern or not!\n",
    "a = seasonal_decompose(data, model = \"add\", period=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,8))\n",
    "a.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly we have monthly seasonality, some extreme residuals can be seen, which also indicate that there might be outlier in the data. trend is not consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data with 80/20 ratio: first split is train and other test\n",
    "# sequence has to be maintained because of time series data\n",
    "\n",
    "N = int(len(data)*0.8)\n",
    "train_data, test_data = data[:N], data[N:]\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_data)\n",
    "train = scaler.transform(train_data)\n",
    "test = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Shape\", train.shape, \"Test shape\", test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The arima code is written with guidance from this page:\n",
    "\n",
    "http://alkaline-ml.com/pmdarima/1.5.1/auto_examples/example_pipeline.html#sphx-glr-auto-examples-example-pipeline-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a pipeline with multiple stages... power dataset seems to be showing monthly seasonality\n",
    "#so we'll include a FourierFeaturizer so we can fit it without seasonality\n",
    "# we have chosen 6 month as seasonal pattern, which will be divided in 75 variable\n",
    "\n",
    "pipe = pipeline.Pipeline([\n",
    "    (\"fourier\", ppc.FourierFeaturizer(m=150, k=75)),\n",
    "    (\"arima\", arima.AutoARIMA(stepwise=True, trace=1, error_action=\"ignore\",\n",
    "                              seasonal=False,  # because we use Fourier\n",
    "                              suppress_warnings=True))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit arima model\n",
    "pipe.fit(train)\n",
    "print(\"Model fit:\")\n",
    "print(pipe)\n",
    "\n",
    "# We can compute predictions the same way we would on a normal ARIMA object:\n",
    "preds, conf_int = pipe.predict(n_periods=20, return_conf_int=True)\n",
    "print(\"\\nForecasts:\")\n",
    "print(preds)\n",
    "\n",
    "\n",
    "# Visualize goodness of fit\n",
    "in_sample_preds, in_sample_confint = \\\n",
    "    pipe.predict_in_sample(exogenous=None, return_conf_int=True)\n",
    "\n",
    "n_train = train.shape[0]\n",
    "\n",
    "\n",
    "# We can also call `update` directly on the pipeline object, which will update\n",
    "# the intermittent transformers, where necessary:\n",
    "newly_observed, still_test = test[:100], test[100:]\n",
    "pipe.update(newly_observed, maxiter=100)\n",
    "\n",
    "# Calling predict will now predict from newly observed values\n",
    "new_preds = pipe.predict(still_test.shape[0])\n",
    "print(new_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the actual vs. the predicted values:\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 8))\n",
    "fig.tight_layout()\n",
    "\n",
    "x0 = np.arange(n_train)\n",
    "axes[0].plot(x0, train, alpha=0.75)\n",
    "axes[0].scatter(x0, in_sample_preds, alpha=0.4, marker='x', color=\"red\")\n",
    "axes[0].set_title('Actual train samples vs. in-sample predictions')\n",
    "axes[0].set_xlim((0, x0.shape[0]))\n",
    "\n",
    "x1 = np.arange(n_train + preds.shape[0])\n",
    "axes[1].plot(x1[:n_train], train, alpha=0.75)\n",
    "axes[1].scatter(x1[n_train:], preds, alpha=0.4, marker='o')\n",
    "axes[1].scatter(x1[n_train:], test[:preds.shape[0]], alpha=0.4, marker='x')\n",
    "axes[1].fill_between(x1[n_train:], conf_int[:, 0], conf_int[:, 1],\n",
    "                     alpha=0.1, color='b')\n",
    "axes[1].set_title('Actual test samples vs. forecasts')\n",
    "axes[1].set_xlim((0, data.shape[0]))\n",
    "\n",
    "x2 = np.arange(data.shape[0])\n",
    "n_trained_on = n_train + newly_observed.shape[0]\n",
    "\n",
    "axes[2].plot(x2[:n_train], train, alpha=0.75)\n",
    "axes[2].plot(x2[n_train: n_trained_on], newly_observed, alpha=0.75, c='orange')\n",
    "axes[2].scatter(x2[n_trained_on:], still_test, alpha=0.4, marker='x', c='red')\n",
    "axes[2].set_title('Actual test samples vs. forecasts')\n",
    "axes[2].set_xlim((0, data.shape[0]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_pr = pipe.predict(test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arima Predictions for test dataset and transformation\n",
    "arima_pr = pipe.predict(test.shape[0])\n",
    "arima_predictions =scaler.inverse_transform(arima_pr.reshape(test.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now merge with test data\n",
    "test_copy = test_data[\"power\"].copy().to_frame()\n",
    "test_copy[\"Arima Predictions\"] = arima_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "test_copy.plot(figsize=(20,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not very impressive!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Step LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(n_neurons=30, input_shape=[1], optimizer='adam'):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.LSTM(input_shape))\n",
    "    model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "# define the grid search parameters\n",
    "optimizers = ['Adam','Nadam', 'Adagrad']\n",
    "neurons = [200, 400, 600, 800, 1000]\n",
    "batch_size = [10,20,30]\n",
    "epoch = [500, 1000]\n",
    "keras_reg = KerasRegressor(build_model)\n",
    "params_distrib = dict(batch_size=batch_size, n_neurons=neurons, optimizer=optimizers,\n",
    "                     epochs=epoch)\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, params_distrib, cv=3,\n",
    "                                   scoring=\"r2\")\n",
    "grid_result = rnd_search_cv.fit(train, train, epochs=50, \n",
    "                    validation_data=(test, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"Mean: %f (Standard Deviation: %f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy\n",
    "plt.plot(grid_result.best_estimator_.model.history.history['accuracy'])\n",
    "plt.plot(grid_result.best_estimator_.model.history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "plt.plot(grid_result.best_estimator_.model.history.history['loss'])\n",
    "plt.plot(grid_result.best_estimator_.model.history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_1_pr = grid_result.predict(test)\n",
    "lstm1_predictions = scaler.inverse_transform(lstm_1_pr.reshape(test.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train.reshape(int(len(train)/5), 5)\n",
    "test2 = test.reshape(int(len(test)/5), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(n_neurons=30, input_shape=[5], optimizer='adam'):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.LSTM(input_shape))\n",
    "    model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(5))\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "keras_reg1 = KerasRegressor(build_model2)\n",
    "params_distrib1 = dict(batch_size=batch_size, n_neurons=neurons, optimizer=optimizers,\n",
    "                     epochs=epoch)\n",
    "rnd_search_cv1 = RandomizedSearchCV(keras_reg1, params_distrib1, cv=3,\n",
    "                                   scoring=\"r2\")\n",
    "grid_result2 = rnd_search_cv1.fit(train2, train2, epochs=50, \n",
    "                    validation_data=(test2, test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result2.best_score_, grid_result2.best_params_))\n",
    "means2 = grid_result2.cv_results_['mean_test_score']\n",
    "stds2 = grid_result2.cv_results_['std_test_score']\n",
    "params2 = grid_result2.cv_results_['params']\n",
    "for mean, stdev, param in zip(means2, stds2, params2):\n",
    "    print(\"Mean: %f (Standard Deviation: %f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy\n",
    "plt.plot(grid_result2.best_estimator_.model.history.history['accuracy'])\n",
    "plt.plot(grid_result2.best_estimator_.model.history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "plt.plot(grid_result2.best_estimator_.model.history.history['loss'])\n",
    "plt.plot(grid_result2.best_estimator_.model.history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_2_pr = grid_result2.predict(test2)\n",
    "lstm2_predictions = scaler.inverse_transform(lstm_2_pr.reshape(test.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3 = train.reshape(int(len(train)/15), 15)\n",
    "test3 = test.reshape(int(len(test)/15),15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15 Step LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model3(n_neurons=30, input_shape=[15], optimizer='adam'):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.LSTM(input_shape))\n",
    "    model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(15))\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "keras_reg2 = KerasRegressor(build_model3)\n",
    "params_distrib2 = dict(batch_size=batch_size, n_neurons=neurons, optimizer=optimizers,\n",
    "                     epochs=epoch)\n",
    "rnd_search_cv2 = RandomizedSearchCV(keras_reg2, params_distrib1, cv=3,\n",
    "                                   scoring=\"r2\")\n",
    "grid_result3 = rnd_search_cv2.fit(train3, train3, epochs=50, \n",
    "                    validation_data=(test3, test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result3.best_score_, grid_result3.best_params_))\n",
    "means3 = grid_result3.cv_results_['mean_test_score']\n",
    "stds3 = grid_result3.cv_results_['std_test_score']\n",
    "params3 = grid_result3.cv_results_['params']\n",
    "for mean, stdev, param in zip(means3, stds3, params3):\n",
    "    print(\"Mean: %f (Standard Deviation: %f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_3_pr = grid_result3.predict(test3)\n",
    "lstm3_predictions = scaler.inverse_transform(lstm_3_pr.reshape(test.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy\n",
    "plt.plot(grid_result3.best_estimator_.model.history.history['accuracy'])\n",
    "plt.plot(grid_result3.best_estimator_.model.history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "plt.plot(grid_result3.best_estimator_.model.history.history['loss'])\n",
    "plt.plot(grid_result3.best_estimator_.model.history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_copy[\"1_step LSTM_Predictions\"] = lstm1_predictions\n",
    "test_copy[\"5_step LSTM_Predictions\"] = lstm2_predictions\n",
    "test_copy[\"15_step LSTM_Predictions\"] = lstm3_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "test_copy.plot(figsize=(20,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM Predictions looks to be more accurate!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot all lstm models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One step and multi step LSTM forecasting graph\n",
    "fig = plt.figure(dpi=700,figsize=(12, 8))\n",
    "aa=test_copy.index\n",
    "#linestyles = ['-', '--', '-.', ':']\n",
    "plt.plot(aa, test_copy[\"power\"], \"b\", linestyle='dashed', marker='*', label=\"Actual\")\n",
    "\n",
    "plt.plot(aa, test_copy[\"1_step LSTM_Predictions\"], 'red', linestyle='dotted', marker = 's',\n",
    "         label=\"1 Step LSTM predictions\")\n",
    "\n",
    "plt.plot(aa, test_copy[\"5_step LSTM_Predictions\"], 'g', marker = '^', linestyle=':',\n",
    "         label=\"5 Step LSTM Predictions\")\n",
    "\n",
    "plt.plot(aa, test_copy[\"15_step LSTM_Predictions\"], 'gray', marker = '>',\n",
    "         label=\"15 Step LSTM Predictions\")\n",
    "\n",
    "sns.despine(top=True)\n",
    "plt.subplots_adjust(left=0.07)\n",
    "plt.ylabel('Global active power', size=20)\n",
    "plt.xlabel('Date', size=15)\n",
    "plt.title(\"LSTM Predictions With different Steps\", fontsize=22, color=\"black\")\n",
    "plt.legend(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA forecasting\n",
    "\n",
    "fig = plt.figure(dpi=700,figsize=(12, 8))\n",
    "aa=test_copy.index\n",
    "plt.plot(aa, test_copy[\"power\"].to_numpy(), marker='*', label=\"Actual\")\n",
    "plt.plot(aa, test_copy[\"Arima Predictions\"].to_numpy(), 'r', marker = 'o',\n",
    "         label=\"Arima Predictions\")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine(top=True)\n",
    "plt.subplots_adjust(left=0.07)\n",
    "plt.ylabel('Global active power', size=20)\n",
    "plt.xlabel('Date', size=15)\n",
    "plt.title(\"ARIMA Predictions\", fontsize=22, color=\"black\")\n",
    "plt.legend(fontsize=15)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_desc = test_copy.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Error metrics\n",
    "def error_metric(b, a = test_copy[\"power\"]):\n",
    "    ms = mse(a,b)\n",
    "    ma = mae(a, b)\n",
    "    r2 = r2_score(a, b)\n",
    "    return (ms, ma, r2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_ar, mae_ar, r_2_ar = error_metric(test_copy[\"Arima Predictions\"])\n",
    "mse1, mae1, r_21 = error_metric(test_copy[\"1_step LSTM_Predictions\"])\n",
    "mse2, mae2, r_22 = error_metric(test_copy[\"5_step LSTM_Predictions\"])\n",
    "mse4, mae4, r_24 = error_metric(test_copy[\"15_step LSTM_Predictions\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Power': ['', '', ''],\n",
    "        'Arima': [mse_ar, mae_ar, r_2_ar],\n",
    "        '1 Step LSTM': [mse1, mae1, r_21],\n",
    "       '5 Step LSTM': [mse2, mae2, r_22],\n",
    "       '15 Step LSTM' : [mse4, mae4, r_24]}\n",
    "\n",
    "error_df = pd.DataFrame.from_dict(data, orient='index', columns=['MSE', 'MAE', \"R-Square\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_desc.columns = error_df.T.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these lines can be removed, if not needed!\n",
    "error_df[\"Mean\"] = ts_desc.T[\"mean\"]\n",
    "error_df[\"SD\"] = ts_desc.T[\"std\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result.cv_results_[\"std_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = pd.concat([pd.DataFrame(grid_result.cv_results_[\"params\"]),\n",
    "                     pd.DataFrame(grid_result.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"]),\n",
    "                     pd.DataFrame(grid_result.cv_results_[\"std_test_score\"], columns=[\"Error\"])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = pd.concat([pd.DataFrame(grid_result2.cv_results_[\"params\"]),\n",
    "                     pd.DataFrame(grid_result2.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"]),\n",
    "                     pd.DataFrame(grid_result2.cv_results_[\"std_test_score\"], columns=[\"Error\"])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = pd.concat([pd.DataFrame(grid_result3.cv_results_[\"params\"]),\n",
    "                     pd.DataFrame(grid_result3.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"]),\n",
    "                     pd.DataFrame(grid_result3.cv_results_[\"std_test_score\"], columns=[\"Error\"])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_results = pd.concat([result1, result2, result3], axis=1, keys=['1 Step', '5 Step', '15 Step'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = step_results.stack(0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.groupby([\"level_1\", \"optimizer\"])[\"Accuracy\"].plot(figsize=(16,12), legend=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.groupby([\"level_1\", \"optimizer\"])[\"Accuracy\"].plot(figsize=(16,12), legend=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets filter based on more than 95% accuracy\n",
    "rr = r[r[\"Accuracy\"] > 0.90].iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
